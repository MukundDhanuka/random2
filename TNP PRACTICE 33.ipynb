{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HYZ6D_dw1A9v-myCrhTM17aeCi14wDNr","timestamp":1714311625724},{"file_id":"15FKV6GaGU5hL4Jyfl2XLtqCHsU7ZDI4x","timestamp":1714292409268}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"DiWaSK59GCvx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714315002761,"user_tz":-330,"elapsed":23103,"user":{"displayName":"20_IT_A_Mukund Dhanuka","userId":"01777061334196894779"}},"outputId":"8930f535-60c2-4d67-8e91-e98877a3eaa1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Data Preprocessing & Exploration\n"],"metadata":{"id":"JFI1-Pyg0G-L"}},{"cell_type":"markdown","source":["1.\tMissing Value Handling:\n","○\tPractical: Use techniques like mean imputation, median imputation, or predictive imputation to handle missing values in datasets.\n","○\tDataset: You can use the \"Adult Income\" dataset from the UCI Machine Learning Repository, which contains missing values in various attributes such as education and occupation. Dataset link\n"],"metadata":{"id":"WSnAXervGdCc"}},{"cell_type":"code","source":["import pandas as pd\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n","           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n","           'hours-per-week', 'native-country', 'income']\n","data = pd.read_csv(url)\n","\n","\n","numeric_columns = data.select_dtypes(include=['int', 'float']).columns\n","data_mean = data.copy()\n","data_mean[numeric_columns] = data_mean[numeric_columns].fillna(data_mean[numeric_columns].mean())\n","\n","numeric_columns = data.select_dtypes(include=['int', 'float']).columns\n","data_median = data.copy()\n","data_median[numeric_columns] = data_median[numeric_columns].fillna(data_median[numeric_columns].median())\n","\n","\n","from sklearn.impute import SimpleImputer\n","\n","data_predictive = data.copy()\n","imp = SimpleImputer(strategy='most_frequent')\n","# data_predictive[['workclass', 'occupation', 'native-country']] = imp.fit_transform(data_predictive[['workclass', 'occupation', 'native-country']])\n","\n","print(\"Mean imputation:\")\n","print(data_mean.head())\n","\n","print(\"\\nMedian imputation:\")\n","print(data_median.head())\n","\n","print(\"\\nPredictive imputation:\")\n","print(data_predictive.head())"],"metadata":{"id":"hfVb7e-0GlRp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.\tOutlier Detection:\n","○\tPractical: Identify and handle outliers in the data using methods like z-score, IQR (Interquartile Range), or visualization techniques.\n","○\tDataset: The \"Credit Card Fraud Detection\" dataset from Kaggle contains transactions with potential outliers representing fraudulent activities. Dataset link\n"],"metadata":{"id":"wU93nZEaywNj"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","# change the 'credit_card_fraud_dataset.csv' to url/csv file\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Z-Score method\n","z_scores = np.abs((df - df.mean()) / df.std())\n","threshold = 3\n","outliers_zscore = df[(z_scores > threshold).any(axis=1)]\n","# print('Z-Score method')\n","# print(outliers_zscore)\n","\n","# IQR method\n","Q1 = df.quantile(0.25)\n","Q3 = df.quantile(0.75)\n","IQR = Q3 - Q1\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","outliers_iqr = df[((df < lower_bound) | (df > upper_bound)).any(axis=1)]\n","# print(\"IQR METHOD\")\n","# print(outliers_iqr)\n","\n","# Visualization - Boxplot\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(data=df)\n","plt.title('Boxplot of Credit Card Fraud Dataset')\n","plt.xticks(rotation=45)\n","plt.show()\n"],"metadata":{"id":"YvjEX0tmIzWS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.\tFeature Scaling:\n","○\tPractical: Normalize or standardize features in the dataset to ensure fair comparisons and improve machine learning model performance.\n","○\tDataset: The \"Wine Quality\" dataset from the UCI Machine Learning Repository includes features related to wine properties that can benefit from feature scaling. Dataset link"],"metadata":{"id":"knrOkdDTy-oF"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","# Load the dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n","df = pd.read_csv(url, sep=';')\n","\n","# Display the first few rows of the dataset\n","print(df.head())\n","\n","# Separate features (attributes) from the target variable\n","X = df.drop('quality', axis=1)  # Features\n","y = df['quality']  # Target variable\n","\n","# Standardization\n","scaler_standard = StandardScaler()\n","X_standardized = scaler_standard.fit_transform(X)\n","\n","# Normalization\n","scaler_minmax = MinMaxScaler()\n","X_normalized = scaler_minmax.fit_transform(X)\n","\n","# Convert the standardized and normalized arrays back to DataFrame for display\n","X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)\n","X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n","\n","# Display the first few rows of the standardized and normalized datasets\n","print(\"\\nStandardized Data:\")\n","print(X_standardized_df.head())\n","\n","print(\"\\nNormalized Data:\")\n","print(X_normalized_df.head())\n"],"metadata":{"id":"qWwdXAzmJ8-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.\tData Visualization:\n","○\tPractical: Explore the dataset visually using plots such as histograms, scatter plots, and box plots to understand data distributions and relationships.\n","○\tDataset: The \"Iris\" dataset is a classic dataset often used for data visualization tasks, showcasing features of different iris flower species. Dataset link\n"],"metadata":{"id":"-A34vG1qzIL-"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n","column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n","df = pd.read_csv(url, names=column_names)\n","\n","# Display the first few rows of the dataset\n","# print(df.head())\n","\n","# Histograms for feature distributions\n","plt.figure(figsize=(10, 6))\n","df.hist(figsize=(10, 8))\n","# plt.tight_layout()\n","# plt.show()\n","\n","# Pairplot for pairwise relationships and distributions\n","plt.figure(figsize=(10, 8))\n","sns.pairplot(df, hue='species')\n","# plt.show()\n","\n","# Box plot for feature distributions by species\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(data=df, x='species', y='sepal_length')\n","plt.title('Sepal Length Distribution by Species')\n","# plt.show()\n"],"metadata":{"id":"uA02wCrTKdpJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Association Rule Mining - Apriori algorithm"],"metadata":{"id":"dtSlq1r_z9nj"}},{"cell_type":"markdown","source":["1.\tFrequent Itemset Mining:\n","○\tExperiment: Use the Apriori algorithm to mine frequent itemsets from transactional data.\n","○\tDataset: The \"Online Retail\" dataset from the UCI Machine Learning Repository contains transactional data from an online retail store, suitable for frequent itemset mining. Dataset link\n","\n"],"metadata":{"id":"f8VKWsCDz7Jp"}},{"cell_type":"code","source":["import pandas as pd\n","from mlxtend.frequent_patterns import apriori\n","from mlxtend.frequent_patterns import association_rules\n","\n","# Load the dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\"\n","df = pd.read_excel(url)\n","df.head()\n","# Data Preprocessing\n","# Remove rows with missing values in 'InvoiceNo' column\n","df.dropna(subset=['InvoiceNo'], inplace=True)\n","\n","# Remove credit transactions (starting with 'C')\n","# df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n","\n","# Remove unnecessary columns\n","# df = df[['InvoiceNo', 'Description']]\n","\n","# Group items by invoice and create transactional dataset\n","transactions = df.groupby('InvoiceNo')['Description'].apply(list)\n","\n","# Convert transactions into one-hot encoded format\n","one_hot_encoded = transactions.str.join('|').str.get_dummies()\n","\n","# Apply the Apriori algorithm\n","frequent_itemsets = apriori(one_hot_encoded, min_support=0.01, use_colnames=True)\n","\n","# Generate association rules\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n","\n","# Display the frequent itemsets and association rules\n","print(\"Frequent Itemsets:\")\n","print(frequent_itemsets)\n","\n","print(\"\\nAssociation Rules:\")\n","print(rules)\n"],"metadata":{"id":"CFslwwizjnBs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c3719d0-c84f-43ee-91fe-d012bb34be19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["2.\tAssociation Rule Generation:\n","○\tExperiment: Generate association rules with specified support and confidence thresholds from the mined frequent itemsets.\n","○\tDataset: The \"Groceries\" dataset from the UCI Machine LearningRepository includes transactional data from a grocery store, ideal for association rule generation tasks. Dataset link\n","\n"],"metadata":{"id":"whplGVfY0RwD"}},{"cell_type":"code","source":["import pandas as pd\n","from mlxtend.frequent_patterns import apriori, association_rules\n","\n","# Load the dataset\n","url = \"/content/drive/MyDrive/Colab Notebooks/DATASETS/Groceries_dataset.csv\"\n","df = pd.read_csv(url)\n","\n","# Data Preprocessing\n","transactions = []\n","for index, row in df.iterrows():\n","    transactions.append([item.strip() for item in row if pd.notna(item)])\n","\n","# Apply the Apriori algorithm\n","one_hot_encoded = pd.get_dummies(pd.DataFrame(transactions).stack()).groupby(level=0).sum()\n","frequent_itemsets = apriori(one_hot_encoded, min_support=0.01, use_colnames=True)\n","\n","# Generate Association Rules\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.5)\n","rules = rules[(rules['support'] >= 0.01) & (rules['confidence'] >= 0.5)]\n","\n","# Display the association rules\n","print(\"Association Rules:\")\n","print(rules)\n"],"metadata":{"id":"mDrsC60Vlxdb","colab":{"base_uri":"https://localhost:8080/","height":387},"executionInfo":{"status":"error","timestamp":1714315471259,"user_tz":-330,"elapsed":827,"user":{"displayName":"20_IT_A_Mukund Dhanuka","userId":"01777061334196894779"}},"outputId":"0d81bbc7-34b4-46eb-fdeb-e9a77ecd5897"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'int' object has no attribute 'strip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ab9a4ef836f2>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtransactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Apply the Apriori algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ab9a4ef836f2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtransactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtransactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Apply the Apriori algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'strip'"]}]},{"cell_type":"markdown","source":["3.\tRule Evaluation and Pruning:\n","○\tExperiment: Evaluate generated association rules based on metrics like lift, Support & confidence. Prune rules based on predefined criteria.\n","○\tDataset: The \"Mushroom\" dataset from the UCI Machine Learning Repository contains data about mushroom species, suitable for association rule evaluation and pruning. Dataset link\n"],"metadata":{"id":"-qXe-2Hg0cEz"}},{"cell_type":"code","source":[],"metadata":{"id":"lMoHax99Io0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from mlxtend.frequent_patterns import apriori, association_rules\n","\n","# Load the dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n","# Define column names based on dataset description\n","column_names = [\"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\", \"gill-attachment\",\n","                \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-root\",\n","                \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n","                \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\",\n","                \"spore-print-color\", \"population\", \"habitat\"]\n","df = pd.read_csv(url, header=None, names=column_names)\n","\n","# Data Preprocessing\n","# Convert categorical variables to dummy variables\n","df_encoded = pd.get_dummies(df)\n","\n","# Apply the Apriori algorithm\n","frequent_itemsets = apriori(df_encoded, min_support=0.3, use_colnames=True)\n","\n","# Generate Association Rules\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n","\n","# Evaluate Association Rules\n","print(\"Association Rules:\")\n","print(rules)\n","\n","# Prune Rules based on predefined criteria\n","min_confidence = 0.7\n","min_lift = 1.5\n","pruned_rules = rules[(rules['confidence'] >= min_confidence) & (rules['lift'] >= min_lift)]\n","\n","# Display pruned rules\n","print(\"\\nPruned Rules:\")\n","print(pruned_rules)\n"],"metadata":{"id":"uLBVLAePnK-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714315059019,"user_tz":-330,"elapsed":1596,"user":{"displayName":"20_IT_A_Mukund Dhanuka","userId":"01777061334196894779"}},"outputId":"b021159e-08be-4e82-f6bb-5797f6471017"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Association Rules:\n","                          antecedents  \\\n","0                           (class_e)   \n","1                         (bruises_t)   \n","2                            (odor_n)   \n","3                           (class_e)   \n","4                       (gill-size_b)   \n","...                               ...   \n","62737  (gill-attachment_f, bruises_t)   \n","62738                   (ring-type_p)   \n","62739    (stalk-surface-below-ring_s)   \n","62740    (stalk-surface-above-ring_s)   \n","62741                     (bruises_t)   \n","\n","                                             consequents  antecedent support  \\\n","0                                            (bruises_t)            0.517971   \n","1                                              (class_e)            0.415559   \n","2                                              (class_e)            0.434269   \n","3                                               (odor_n)            0.517971   \n","4                                              (class_e)            0.690793   \n","...                                                  ...                 ...   \n","62737  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.415559   \n","62738  (veil-color_w, veil-type_p, stalk-surface-belo...            0.488429   \n","62739  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.607582   \n","62740  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.637125   \n","62741  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.415559   \n","\n","       consequent support   support  confidence      lift  leverage  \\\n","0                0.415559  0.338749    0.653992  1.573766  0.123502   \n","1                0.517971  0.338749    0.815166  1.573766  0.123502   \n","2                0.517971  0.419498    0.965986  1.864941  0.194559   \n","3                0.434269  0.419498    0.809886  1.864941  0.194559   \n","4                0.517971  0.482521    0.698503  1.348536  0.124710   \n","...                   ...       ...         ...       ...       ...   \n","62737            0.339734  0.316100    0.760664  2.238996  0.174921   \n","62738            0.316100  0.316100    0.647177  2.047379  0.161708   \n","62739            0.348597  0.316100    0.520259  1.492439  0.104299   \n","62740            0.324963  0.316100    0.496136  1.526746  0.109058   \n","62741            0.339734  0.316100    0.760664  2.238996  0.174921   \n","\n","       conviction  zhangs_metric  \n","0        1.689099       0.756348  \n","1        2.607898       0.623812  \n","2       14.171640       0.819807  \n","3        2.975746       0.962163  \n","4        1.598785       0.835864  \n","...           ...            ...  \n","62737    2.758735       0.946838  \n","62738    1.938367       1.000000  \n","62739    1.357824       0.840828  \n","62740    1.339721       0.950773  \n","62741    2.758735       0.946838  \n","\n","[62742 rows x 10 columns]\n","\n","Pruned Rules:\n","                                   antecedents  \\\n","1                                  (bruises_t)   \n","2                                     (odor_n)   \n","3                                    (class_e)   \n","10                               (ring-type_p)   \n","11                                   (class_e)   \n","...                                        ...   \n","62734  (stalk-surface-above-ring_s, bruises_t)   \n","62735              (gill-spacing_c, bruises_t)   \n","62736               (ring-number_o, bruises_t)   \n","62737           (gill-attachment_f, bruises_t)   \n","62741                              (bruises_t)   \n","\n","                                             consequents  antecedent support  \\\n","1                                              (class_e)            0.415559   \n","2                                              (class_e)            0.434269   \n","3                                               (odor_n)            0.517971   \n","10                                             (class_e)            0.488429   \n","11                                         (ring-type_p)            0.517971   \n","...                                                  ...                 ...   \n","62734  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.397834   \n","62735  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.402757   \n","62736  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.379124   \n","62737  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.415559   \n","62741  (veil-color_w, veil-type_p, ring-type_p, stalk...            0.415559   \n","\n","       consequent support   support  confidence      lift  leverage  \\\n","1                0.517971  0.338749    0.815166  1.573766  0.123502   \n","2                0.517971  0.419498    0.965986  1.864941  0.194559   \n","3                0.434269  0.419498    0.809886  1.864941  0.194559   \n","10               0.517971  0.387986    0.794355  1.533588  0.134994   \n","11               0.488429  0.387986    0.749049  1.533588  0.134994   \n","...                   ...       ...         ...       ...       ...   \n","62734            0.348597  0.316100    0.794554  2.279294  0.177417   \n","62735            0.364353  0.316100    0.784841  2.154071  0.169355   \n","62736            0.352536  0.316100    0.833766  2.365055  0.182446   \n","62737            0.339734  0.316100    0.760664  2.238996  0.174921   \n","62741            0.339734  0.316100    0.760664  2.238996  0.174921   \n","\n","       conviction  zhangs_metric  \n","1        2.607898       0.623812  \n","2       14.171640       0.819807  \n","3        2.975746       0.962163  \n","10       2.343982       0.680130  \n","11       2.038532       0.721813  \n","...           ...            ...  \n","62734    3.170686       0.932081  \n","62735    2.954316       0.897060  \n","62736    3.894902       0.929616  \n","62737    2.758735       0.946838  \n","62741    2.758735       0.946838  \n","\n","[35913 rows x 10 columns]\n"]}]},{"cell_type":"markdown","source":["4.\tRule Visualization and Interpretation:\n","○\tExperiment: Visualize the generated association rules using graphs or charts for better understanding and interpretation.\n","○\tDataset: The \"Market Basket Optimisation\" dataset from Kaggle consists of transactional data from a grocery store, providing opportunities for rule visualization and interpretation\n"],"metadata":{"id":"LwH-gadp0e-d"}},{"cell_type":"code","source":["import pandas as pd\n","from mlxtend.frequent_patterns import apriori, association_rules\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset maam ne nhi diya hai lol dumb-fuck -kawal\n","url = \"link\"\n","df = pd.read_csv(url)\n","\n","# Data Preprocessing\n","# Convert data into transaction format\n","transactions = df.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).reset_index(name='items')\n","\n","# One-hot encode the data\n","one_hot_encoded = transactions['items'].str.join('|').str.get_dummies('|')\n","\n","# Apply the Apriori algorithm\n","frequent_itemsets = apriori(one_hot_encoded, min_support=0.01, use_colnames=True)\n","\n","# Generate Association Rules\n","rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n","\n","# Visualize Association Rules using Network Graph\n","G = nx.DiGraph()\n","for idx, rule in rules.iterrows():\n","    G.add_edge(rule['antecedents'], rule['consequents'], weight=rule['lift'])\n","\n","plt.figure(figsize=(15, 10))\n","pos = nx.spring_layout(G)\n","nx.draw_networkx_nodes(G, pos, node_size=2000)\n","nx.draw_networkx_labels(G, pos, font_size=10)\n","edges = nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=20, edge_color='b', width=2)\n","plt.title(\"Association Rules Network Graph\")\n","plt.show()\n"],"metadata":{"id":"T784OdP_nmbK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Classification: Naive Bayes Algorithm"],"metadata":{"id":"cGj-ZJQb0kOY"}},{"cell_type":"markdown","source":["1.\tSpam Email Classification:\n","○\tPractical: Train a Naive Bayes classifier to distinguish between spam and non-spam emails based on text features.\n","○\tDataset: The \"Spambase\" dataset from the UCI Machine Learning Repository contains email spam and non-spam data, ideal for spam classification tasks. Dataset link\n"],"metadata":{"id":"vAxyl9g_0q9C"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load the dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n","df = pd.read_csv(url, header=None)\n","\n","# Determine the number of columns in the dataset\n","num_columns = df.shape[1]\n","\n","# Generate generic column names\n","column_names = [f\"X{i}\" for i in range(num_columns - 1)] + [\"spam\"]\n","\n","# Assign column names to the DataFrame\n","df.columns = column_names\n","\n","# Data Preprocessing\n","X = df.drop(\"spam\", axis=1)  # Features\n","y = df[\"spam\"]  # Target variable\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the Naive Bayes classifier\n","nb_classifier = GaussianNB()\n","nb_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred = nb_classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n"],"metadata":{"id":"XmQq-Ap5ohkp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# #Clustering: K means algorithm"],"metadata":{"id":"NAliKh9Ahw5d"}},{"cell_type":"markdown","source":["1.\tCustomer Segmentation:\n","○\tPractical: Use K-means clustering to segment customers based on their purchasing behavior and demographics.\n","○\tDataset: The \"Mall Customer Segmentation Data\" from Kaggle contains information about customers such as age, income, and spending score, suitable for customer segmentation tasks. Dataset link\n"],"metadata":{"id":"94d1FVaHiKzd"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","\n","# Load the customer data\n","customer_data = pd.read_csv(r'/content/drive/MyDrive/dataset /dataset/Mall_Customers.csv')  # Replace 'customer_data.csv' with your dataset path\n","\n","# Print the columns to identify the correct column names\n","print(customer_data.columns)\n","\n","# Preprocess the data\n","# For illustration purposes, let's assume the data is already preprocessed and scaled\n","# If needed, handle missing values, encode categorical variables, and scale the features\n","\n","# Select relevant features for clustering\n","features = customer_data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","scaled_features = scaler.fit_transform(features)\n","\n","# Choose the number of clusters\n","num_clusters = 4  # For illustration, you can determine the optimal number of clusters using techniques like the elbow method\n","\n","# Apply K-means clustering\n","kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n","kmeans.fit(scaled_features)\n","\n","# Add cluster labels to the original data\n","customer_data['Cluster'] = kmeans.labels_\n","# Label encoding for categorical variable 'Gender'\n","customer_data['Gender'] = customer_data['Gender'].astype('category').cat.codes\n","\n","\n","# Visualize the clusters\n","plt.figure(figsize=(8, 6))\n","for cluster in range(num_clusters):\n","    cluster_data = customer_data[customer_data['Cluster'] == cluster]\n","    plt.scatter(cluster_data['Annual Income (k$)'], cluster_data['Spending Score (1-100)'], label=f'Cluster {cluster}')\n","plt.xlabel('Annual Income (k$)')\n","plt.ylabel('Spending Score (1-100)')\n","plt.title('Customer Segmentation')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Profile each cluster\n","cluster_profiles = customer_data.groupby('Cluster').mean()\n","print(\"Cluster Profiles:\")\n","print(cluster_profiles)\n"],"metadata":{"id":"6zAFKGbXiKW9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.\tImage Compression:\n","○\tPractical: Apply K-means clustering to compress images by reducing the number of colors while preserving image quality.\n","○\tDataset: You can use images from public repositories or create your own dataset of images for image compression experiments.\n"],"metadata":{"id":"QNgRumomhuxS"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from skimage import io\n","\n","# Load the image\n","image = io.imread('/content/drive/MyDrive/Screenshot_2020-09-07-18-03-30-723_com.tencent.ig.jpg')  # Replace 'your_image.jpg' with the path to your image\n","\n","# Reshape the image into a 2D array\n","w, h, d = original_shape = tuple(image.shape)\n","image_array = np.reshape(image, (w * h, d))\n","\n","# Apply K-means clustering\n","n_colors = 16  # Number of colors to reduce to\n","kmeans = KMeans(n_clusters=n_colors, random_state=0)\n","kmeans.fit(image_array)\n","\n","# Predict the cluster labels for each pixel\n","labels = kmeans.predict(image_array)\n","\n","# Replace each pixel with its centroid value\n","compressed_image = np.zeros((w, h, d), dtype=np.uint8)\n","label_idx = 0\n","for i in range(w):\n","    for j in range(h):\n","        compressed_image[i][j] = kmeans.cluster_centers_[labels[label_idx]]\n","        label_idx += 1\n","\n","# Display the original and compressed images\n","fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n","axes[0].imshow(image)\n","axes[0].set_title('Original Image')\n","axes[0].axis('off')\n","axes[1].imshow(compressed_image)\n","axes[1].set_title('Compressed Image ({} colors)'.format(n_colors))\n","axes[1].axis('off')\n","plt.show()\n"],"metadata":{"id":"SbmGsbhTtIP6"},"execution_count":null,"outputs":[]}]}